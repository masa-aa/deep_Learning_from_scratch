{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.core.display import display\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# build model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dropout, Reshape, Flatten, Conv2D, MaxPooling2D, Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nreshape (Reshape)            (None, 28, 28, 1)         0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 28, 28, 16)        160       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 28, 28, 16)        2320      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 14, 14, 32)        4640      \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 14, 14, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 7, 7, 32)          9248      \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 7, 7, 32)          9248      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 3, 3, 32)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 288)               0         \n_________________________________________________________________\ndense (Dense)                (None, 288)               83232     \n_________________________________________________________________\ndropout (Dropout)            (None, 288)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 288)               83232     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 288)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                2890      \n=================================================================\nTotal params: 204,218\nTrainable params: 204,218\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "def DeepNeuralNetwork():\n",
    "    \"\"\"\n",
    "    input ->\n",
    "    Conv -> ReLU -> Conv -> ReLU -> Pool ->\n",
    "    Conv -> ReLU -> Conv -> ReLU -> Pool ->\n",
    "    Conv -> ReLU -> Conv -> ReLU -> Pool ->\n",
    "    Affine -> ReLU -> Dropout ->\n",
    "    Affine -> Dropout -> Softmax ->\n",
    "    output\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(28, 28)))\n",
    "    model.add(Reshape((28, 28, 1)))\n",
    "\n",
    "    # 1\n",
    "    model.add(Conv2D(16, 3, activation='relu', bias_initializer='he_normal', padding=\"same\"))\n",
    "    model.add(Conv2D(16, 3, activation='relu', bias_initializer='he_normal', padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # 2\n",
    "    model.add(Conv2D(32, 3, activation='relu', bias_initializer='he_normal', padding=\"same\"))\n",
    "    model.add(Conv2D(32, 3, activation='relu', bias_initializer='he_normal', padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # 3\n",
    "    model.add(Conv2D(32, 3, activation='relu', bias_initializer='he_normal', padding=\"same\"))\n",
    "    model.add(Conv2D(32, 3, activation='relu', bias_initializer='he_normal', padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # 全結合層\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(288, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(288))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = DeepNeuralNetwork()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples\nEpoch 1/20\n60000/60000 [==============================] - 4s 59us/sample - loss: 0.3973 - acc: 0.8930\nEpoch 2/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0868 - acc: 0.9741\nEpoch 3/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0642 - acc: 0.9811\nEpoch 4/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0537 - acc: 0.9844\nEpoch 5/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0505 - acc: 0.9860\nEpoch 6/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0430 - acc: 0.9876\nEpoch 7/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0385 - acc: 0.9891\nEpoch 8/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0376 - acc: 0.9895\nEpoch 9/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0378 - acc: 0.9895\nEpoch 10/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0358 - acc: 0.9902\nEpoch 11/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0340 - acc: 0.9906\nEpoch 12/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0316 - acc: 0.9913\nEpoch 13/20\n60000/60000 [==============================] - 2s 31us/sample - loss: 0.0253 - acc: 0.9931\nEpoch 14/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0297 - acc: 0.9917\nEpoch 15/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0308 - acc: 0.9916\nEpoch 16/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0254 - acc: 0.9931\nEpoch 17/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0291 - acc: 0.9919\nEpoch 18/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0270 - acc: 0.9928\nEpoch 19/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0256 - acc: 0.9930\nEpoch 20/20\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.0216 - acc: 0.9941\n"
    }
   ],
   "source": [
    "\n",
    "# f_model = './model'\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "# cp_cb = ModelCheckpoint(filepath = os.path.join(f_model,'cnn_model{epoch:02d}-loss{loss:.2f}-acc{acc:.2f}-vloss{val_loss:.2f}-vacc{val_acc:.2f}.hdf5'), monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "history = model.fit(x=x_train, y=y_train, epochs=20, batch_size=100, shuffle=True, validation_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train score: 0.009193204807042839\nTrain accuracy: 0.9975167\nTest score: 0.04042240088165163\nTest accuracy: 0.9922\n"
    }
   ],
   "source": [
    "score0 = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train score:', score0[0])\n",
    "print('Train accuracy:', score0[1])\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# print('save the architecture of a model')\n",
    "# json_string = model.to_json()\n",
    "# open(os.path.join(f_model, 'cnn_model.json'), 'w').write(json_string)\n",
    "# yaml_string = model.to_yaml()\n",
    "# open(os.path.join(f_model, 'cnn_model.yaml'), 'w').write(yaml_string)\n",
    "# print('save weights')\n",
    "# model.save_weights(os.path.join(f_model, 'cnn_model_weights.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python_defaultSpec_1597770112648",
   "display_name": "Python 3.7.7 64-bit ('ML': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}